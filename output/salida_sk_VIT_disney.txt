 dataset local
loading  download (1).png      cat= 0
loading  images (1).jpg      cat= 0
loading  images (1).png      cat= 0
loading  images (2).jpg      cat= 0
loading  images (2).png      cat= 0
loading  images (3).jpg      cat= 0
loading  images.jpg      cat= 0
loading  images.png      cat= 0
loading  th-1067221006      cat= 0
loading  th-1179134170      cat= 0
loading  th-1549400110      cat= 0
loading  th-1643089438      cat= 0
loading  th-2082676030      cat= 0
loading  th-2185767480      cat= 0
loading  th-2187598918      cat= 0
loading  th-2234183508      cat= 0
loading  th-2406436838      cat= 0
loading  th-2448904328      cat= 0
loading  th-2600981176      cat= 0
loading  th-2806259350      cat= 0
loading  th-2953447648      cat= 0
loading  th-3326068090      cat= 0
loading  th-342072390      cat= 0
loading  th-3550922646      cat= 0
loading  th-3700750050      cat= 0
loading  th-383029914      cat= 0
loading  th-383135810      cat= 0
loading  th-4123103249      cat= 0
loading  th-4150869338      cat= 0
loading  th-4169914079      cat= 0
loading  th-4203419010      cat= 0
loading  th-504829466      cat= 0
loading  th-576996926      cat= 0
loading  th-744039594      cat= 0
loading  th-806602408      cat= 0
loading  th-80919584      cat= 0
loading  th-923604970      cat= 0
loading  th-93943714      cat= 0
loading  download.png      cat= 1
loading  images (1).jpg      cat= 1
loading  images (1).png      cat= 1
loading  images (2).jpg      cat= 1
loading  images (2).png      cat= 1
loading  images (3).jpg      cat= 1
loading  images (4).jpg      cat= 1
loading  images (5).jpg      cat= 1
loading  images (6).jpg      cat= 1
loading  images (7).jpg      cat= 1
loading  images.jpg      cat= 1
loading  images.png      cat= 1
loading  th-2236143910      cat= 1
loading  th-2421958470      cat= 1
loading  th-2612963736      cat= 1
loading  th-2620319738      cat= 1
loading  th-2638157814      cat= 1
loading  th-2723996678      cat= 1
loading  th-3023474086      cat= 1
loading  th-3103699962      cat= 1
loading  th-329180654      cat= 1
loading  th-3332595734      cat= 1
loading  th-3669750354      cat= 1
loading  th-3985705512      cat= 1
loading  th-4281491418      cat= 1
loading  th-722788862      cat= 1
loading  th-796734106      cat= 1
loading  images (1).jpg      cat= 2
loading  images (1).png      cat= 2
loading  images (2).jpg      cat= 2
loading  images (3).jpg      cat= 2
loading  images (4).jpg      cat= 2
loading  images (5).jpg      cat= 2
loading  images.jpg      cat= 2
loading  images.png      cat= 2
loading  th-1007463368      cat= 2
loading  th-1260971512      cat= 2
loading  th-1467884172      cat= 2
loading  th-1718183576      cat= 2
loading  th-1821132330      cat= 2
loading  th-2817887764      cat= 2
loading  th-2870333306      cat= 2
loading  th-3107365090      cat= 2
loading  th-3208470906      cat= 2
loading  th-3237651430      cat= 2
loading  th-355663888      cat= 2
loading  th-782857608      cat= 2
loading  th-991343278      cat= 2
x_train.shape (86,)

 dataset local
loading  download (1).png      cat= 0
loading  images (1).jpg      cat= 0
loading  images (1).png      cat= 0
loading  images (2).jpg      cat= 0
loading  images (2).png      cat= 0
loading  images (3).jpg      cat= 0
loading  images.jpg      cat= 0
loading  images.png      cat= 0
loading  th-1067221006      cat= 0
loading  th-1179134170      cat= 0
loading  th-1549400110      cat= 0
loading  th-1643089438      cat= 0
loading  th-2082676030      cat= 0
loading  th-2185767480      cat= 0
loading  th-2187598918      cat= 0
loading  th-2234183508      cat= 0
loading  th-2406436838      cat= 0
loading  th-2448904328      cat= 0
loading  th-2600981176      cat= 0
loading  th-2806259350      cat= 0
loading  th-2953447648      cat= 0
loading  th-3326068090      cat= 0
loading  th-342072390      cat= 0
loading  th-3550922646      cat= 0
loading  th-3700750050      cat= 0
loading  th-383029914      cat= 0
loading  th-383135810      cat= 0
loading  th-4123103249      cat= 0
loading  th-4150869338      cat= 0
loading  th-4169914079      cat= 0
loading  th-4203419010      cat= 0
loading  th-504829466      cat= 0
loading  th-576996926      cat= 0
loading  th-744039594      cat= 0
loading  th-806602408      cat= 0
loading  th-80919584      cat= 0
loading  th-923604970      cat= 0
loading  th-93943714      cat= 0
loading  download.png      cat= 1
loading  images (1).jpg      cat= 1
loading  images (1).png      cat= 1
loading  images (2).jpg      cat= 1
loading  images (2).png      cat= 1
loading  images (3).jpg      cat= 1
loading  images (4).jpg      cat= 1
loading  images (5).jpg      cat= 1
loading  images (6).jpg      cat= 1
loading  images (7).jpg      cat= 1
loading  images.jpg      cat= 1
loading  images.png      cat= 1
loading  th-2236143910      cat= 1
loading  th-2421958470      cat= 1
loading  th-2612963736      cat= 1
loading  th-2620319738      cat= 1
loading  th-2638157814      cat= 1
loading  th-2723996678      cat= 1
loading  th-3023474086      cat= 1
loading  th-3103699962      cat= 1
loading  th-329180654      cat= 1
loading  th-3332595734      cat= 1
loading  th-3669750354      cat= 1
loading  th-3985705512      cat= 1
loading  th-4281491418      cat= 1
loading  th-722788862      cat= 1
loading  th-796734106      cat= 1
loading  images (1).jpg      cat= 2
loading  images (1).png      cat= 2
loading  images (2).jpg      cat= 2
loading  images (3).jpg      cat= 2
loading  images (4).jpg      cat= 2
loading  images (5).jpg      cat= 2
loading  images.jpg      cat= 2
loading  images.png      cat= 2
loading  th-1007463368      cat= 2
loading  th-1260971512      cat= 2
loading  th-1467884172      cat= 2
loading  th-1718183576      cat= 2
loading  th-1821132330      cat= 2
loading  th-2817887764      cat= 2
loading  th-2870333306      cat= 2
loading  th-3107365090      cat= 2
loading  th-3208470906      cat= 2
loading  th-3237651430      cat= 2
loading  th-355663888      cat= 2
loading  th-782857608      cat= 2
loading  th-991343278      cat= 2
x_train.shape (86,)

 dataset local
loading  download (1).png      cat= 0
loading  images (1).jpg      cat= 0
loading  images (1).png      cat= 0
loading  images (2).jpg      cat= 0
loading  images (2).png      cat= 0
loading  images (3).jpg      cat= 0
loading  images.jpg      cat= 0
loading  images.png      cat= 0
loading  th-1067221006      cat= 0
loading  th-1179134170      cat= 0
loading  th-1549400110      cat= 0
loading  th-1643089438      cat= 0
loading  th-2082676030      cat= 0
loading  th-2185767480      cat= 0
loading  th-2187598918      cat= 0
loading  th-2234183508      cat= 0
loading  th-2406436838      cat= 0
loading  th-2448904328      cat= 0
loading  th-2600981176      cat= 0
loading  th-2806259350      cat= 0
loading  th-2953447648      cat= 0
loading  th-3326068090      cat= 0
loading  th-342072390      cat= 0
loading  th-3550922646      cat= 0
loading  th-3700750050      cat= 0
loading  th-383029914      cat= 0
loading  th-383135810      cat= 0
loading  th-4123103249      cat= 0
loading  th-4150869338      cat= 0
loading  th-4169914079      cat= 0
loading  th-4203419010      cat= 0
loading  th-504829466      cat= 0
loading  th-576996926      cat= 0
loading  th-744039594      cat= 0
loading  th-806602408      cat= 0
loading  th-80919584      cat= 0
loading  th-923604970      cat= 0
loading  th-93943714      cat= 0
loading  download.png      cat= 1
loading  images (1).jpg      cat= 1
loading  images (1).png      cat= 1
loading  images (2).jpg      cat= 1
loading  images (2).png      cat= 1
loading  images (3).jpg      cat= 1
loading  images (4).jpg      cat= 1
loading  images (5).jpg      cat= 1
loading  images (6).jpg      cat= 1
loading  images (7).jpg      cat= 1
loading  images.jpg      cat= 1
loading  images.png      cat= 1
loading  th-2236143910      cat= 1
loading  th-2421958470      cat= 1
loading  th-2612963736      cat= 1
loading  th-2620319738      cat= 1
loading  th-2638157814      cat= 1
loading  th-2723996678      cat= 1
loading  th-3023474086      cat= 1
loading  th-3103699962      cat= 1
loading  th-329180654      cat= 1
loading  th-3332595734      cat= 1
loading  th-3669750354      cat= 1
loading  th-3985705512      cat= 1
loading  th-4281491418      cat= 1
loading  th-722788862      cat= 1
loading  th-796734106      cat= 1
loading  images (1).jpg      cat= 2
loading  images (1).png      cat= 2
loading  images (2).jpg      cat= 2
loading  images (3).jpg      cat= 2
loading  images (4).jpg      cat= 2
loading  images (5).jpg      cat= 2
loading  images.jpg      cat= 2
loading  images.png      cat= 2
loading  th-1007463368      cat= 2
loading  th-1260971512      cat= 2
loading  th-1467884172      cat= 2
loading  th-1718183576      cat= 2
loading  th-1821132330      cat= 2
loading  th-2817887764      cat= 2
loading  th-2870333306      cat= 2
loading  th-3107365090      cat= 2
loading  th-3208470906      cat= 2
loading  th-3237651430      cat= 2
loading  th-355663888      cat= 2
loading  th-782857608      cat= 2
loading  th-991343278      cat= 2
x_train.shape (86,)

======================================
Skynnet Info: Longitud de los datos de la subred (datos,etiquetas): 65 65
Skynnet Info: Categorias de esta subred [0 1]
======================================
num patches=  36
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 36, 36, 3)]  0           []                               
                                                                                                  
 data_augmentation (Sequential)  (None, 36, 36, 3)   0           ['input_1[0][0]']                
                                                                                                  
 patches (Patches)              (None, None, 108)    0           ['data_augmentation[0][0]']      
                                                                                                  
 patch_encoder (PatchEncoder)   (None, 36, 22)       3190        ['patches[0][0]']                
                                                                                                  
 layer_normalization (LayerNorm  (None, 36, 22)      44          ['patch_encoder[0][0]']          
 alization)                                                                                       
                                                                                                  
 multi_head_attention (MultiHea  (None, 36, 22)      16038       ['layer_normalization[0][0]',    
 dAttention)                                                      'layer_normalization[0][0]']    
                                                                                                  
 add (Add)                      (None, 36, 22)       0           ['multi_head_attention[0][0]',   
                                                                  'patch_encoder[0][0]']          
                                                                                                  
 layer_normalization_1 (LayerNo  (None, 36, 22)      44          ['add[0][0]']                    
 rmalization)                                                                                     
                                                                                                  
 dense_1 (Dense)                (None, 36, 512)      11776       ['layer_normalization_1[0][0]']  
                                                                                                  
 dropout (Dropout)              (None, 36, 512)      0           ['dense_1[0][0]']                
                                                                                                  
 dense_2 (Dense)                (None, 36, 22)       11286       ['dropout[0][0]']                
                                                                                                  
 dropout_1 (Dropout)            (None, 36, 22)       0           ['dense_2[0][0]']                
                                                                                                  
 add_1 (Add)                    (None, 36, 22)       0           ['dropout_1[0][0]',              
                                                                  'add[0][0]']                    
                                                                                                  
 layer_normalization_2 (LayerNo  (None, 36, 22)      44          ['add_1[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_1 (MultiH  (None, 36, 22)      16038       ['layer_normalization_2[0][0]',  
 eadAttention)                                                    'layer_normalization_2[0][0]']  
                                                                                                  
 add_2 (Add)                    (None, 36, 22)       0           ['multi_head_attention_1[0][0]', 
                                                                  'add_1[0][0]']                  
                                                                                                  
 layer_normalization_3 (LayerNo  (None, 36, 22)      44          ['add_2[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_3 (Dense)                (None, 36, 512)      11776       ['layer_normalization_3[0][0]']  
                                                                                                  
 dropout_2 (Dropout)            (None, 36, 512)      0           ['dense_3[0][0]']                
                                                                                                  
 dense_4 (Dense)                (None, 36, 22)       11286       ['dropout_2[0][0]']              
                                                                                                  
 dropout_3 (Dropout)            (None, 36, 22)       0           ['dense_4[0][0]']                
                                                                                                  
 add_3 (Add)                    (None, 36, 22)       0           ['dropout_3[0][0]',              
                                                                  'add_2[0][0]']                  
                                                                                                  
 layer_normalization_4 (LayerNo  (None, 36, 22)      44          ['add_3[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_2 (MultiH  (None, 36, 22)      16038       ['layer_normalization_4[0][0]',  
 eadAttention)                                                    'layer_normalization_4[0][0]']  
                                                                                                  
 add_4 (Add)                    (None, 36, 22)       0           ['multi_head_attention_2[0][0]', 
                                                                  'add_3[0][0]']                  
                                                                                                  
 layer_normalization_5 (LayerNo  (None, 36, 22)      44          ['add_4[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_5 (Dense)                (None, 36, 512)      11776       ['layer_normalization_5[0][0]']  
                                                                                                  
 dropout_4 (Dropout)            (None, 36, 512)      0           ['dense_5[0][0]']                
                                                                                                  
 dense_6 (Dense)                (None, 36, 22)       11286       ['dropout_4[0][0]']              
                                                                                                  
 dropout_5 (Dropout)            (None, 36, 22)       0           ['dense_6[0][0]']                
                                                                                                  
 add_5 (Add)                    (None, 36, 22)       0           ['dropout_5[0][0]',              
                                                                  'add_4[0][0]']                  
                                                                                                  
 layer_normalization_6 (LayerNo  (None, 36, 22)      44          ['add_5[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 flatten (Flatten)              (None, 792)          0           ['layer_normalization_6[0][0]']  
                                                                                                  
 dropout_6 (Dropout)            (None, 792)          0           ['flatten[0][0]']                
                                                                                                  
 dense_7 (Dense)                (None, 171)          135603      ['dropout_6[0][0]']              
                                                                                                  
 dropout_7 (Dropout)            (None, 171)          0           ['dense_7[0][0]']                
                                                                                                  
 dense_8 (Dense)                (None, 2)            344         ['dropout_7[0][0]']              
                                                                                                  
==================================================================================================
Total params: 256,745
Trainable params: 256,745
Non-trainable params: 0
__________________________________________________________________________________________________
None
======================================
Skynnet Info: Longitud de los datos de la subred (datos,etiquetas): 59 59
Skynnet Info: Categorias de esta subred [0 2]
======================================
num patches=  36
Model: "model_1"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_2 (InputLayer)           [(None, 36, 36, 3)]  0           []                               
                                                                                                  
 data_augmentation (Sequential)  (None, 36, 36, 3)   0           ['input_2[0][0]']                
                                                                                                  
 patches_1 (Patches)            (None, None, 108)    0           ['data_augmentation[0][0]']      
                                                                                                  
 patch_encoder_1 (PatchEncoder)  (None, 36, 22)      3190        ['patches_1[0][0]']              
                                                                                                  
 layer_normalization_7 (LayerNo  (None, 36, 22)      44          ['patch_encoder_1[0][0]']        
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_3 (MultiH  (None, 36, 22)      16038       ['layer_normalization_7[0][0]',  
 eadAttention)                                                    'layer_normalization_7[0][0]']  
                                                                                                  
 add_6 (Add)                    (None, 36, 22)       0           ['multi_head_attention_3[0][0]', 
                                                                  'patch_encoder_1[0][0]']        
                                                                                                  
 layer_normalization_8 (LayerNo  (None, 36, 22)      44          ['add_6[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 dense_10 (Dense)               (None, 36, 512)      11776       ['layer_normalization_8[0][0]']  
                                                                                                  
 dropout_8 (Dropout)            (None, 36, 512)      0           ['dense_10[0][0]']               
                                                                                                  
 dense_11 (Dense)               (None, 36, 22)       11286       ['dropout_8[0][0]']              
                                                                                                  
 dropout_9 (Dropout)            (None, 36, 22)       0           ['dense_11[0][0]']               
                                                                                                  
 add_7 (Add)                    (None, 36, 22)       0           ['dropout_9[0][0]',              
                                                                  'add_6[0][0]']                  
                                                                                                  
 layer_normalization_9 (LayerNo  (None, 36, 22)      44          ['add_7[0][0]']                  
 rmalization)                                                                                     
                                                                                                  
 multi_head_attention_4 (MultiH  (None, 36, 22)      16038       ['layer_normalization_9[0][0]',  
 eadAttention)                                                    'layer_normalization_9[0][0]']  
                                                                                                  
 add_8 (Add)                    (None, 36, 22)       0           ['multi_head_attention_4[0][0]', 
                                                                  'add_7[0][0]']                  
                                                                                                  
 layer_normalization_10 (LayerN  (None, 36, 22)      44          ['add_8[0][0]']                  
 ormalization)                                                                                    
                                                                                                  
 dense_12 (Dense)               (None, 36, 512)      11776       ['layer_normalization_10[0][0]'] 
                                                                                                  
 dropout_10 (Dropout)           (None, 36, 512)      0           ['dense_12[0][0]']               
                                                                                                  
 dense_13 (Dense)               (None, 36, 22)       11286       ['dropout_10[0][0]']             
                                                                                                  
 dropout_11 (Dropout)           (None, 36, 22)       0           ['dense_13[0][0]']               
                                                                                                  
 add_9 (Add)                    (None, 36, 22)       0           ['dropout_11[0][0]',             
                                                                  'add_8[0][0]']                  
                                                                                                  
 layer_normalization_11 (LayerN  (None, 36, 22)      44          ['add_9[0][0]']                  
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_5 (MultiH  (None, 36, 22)      16038       ['layer_normalization_11[0][0]', 
 eadAttention)                                                    'layer_normalization_11[0][0]'] 
                                                                                                  
 add_10 (Add)                   (None, 36, 22)       0           ['multi_head_attention_5[0][0]', 
                                                                  'add_9[0][0]']                  
                                                                                                  
 layer_normalization_12 (LayerN  (None, 36, 22)      44          ['add_10[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 dense_14 (Dense)               (None, 36, 512)      11776       ['layer_normalization_12[0][0]'] 
                                                                                                  
 dropout_12 (Dropout)           (None, 36, 512)      0           ['dense_14[0][0]']               
                                                                                                  
 dense_15 (Dense)               (None, 36, 22)       11286       ['dropout_12[0][0]']             
                                                                                                  
 dropout_13 (Dropout)           (None, 36, 22)       0           ['dense_15[0][0]']               
                                                                                                  
 add_11 (Add)                   (None, 36, 22)       0           ['dropout_13[0][0]',             
                                                                  'add_10[0][0]']                 
                                                                                                  
 layer_normalization_13 (LayerN  (None, 36, 22)      44          ['add_11[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 flatten_1 (Flatten)            (None, 792)          0           ['layer_normalization_13[0][0]'] 
                                                                                                  
 dropout_14 (Dropout)           (None, 792)          0           ['flatten_1[0][0]']              
                                                                                                  
 dense_16 (Dense)               (None, 171)          135603      ['dropout_14[0][0]']             
                                                                                                  
 dropout_15 (Dropout)           (None, 171)          0           ['dense_16[0][0]']               
                                                                                                  
 dense_17 (Dense)               (None, 2)            344         ['dropout_15[0][0]']             
                                                                                                  
==================================================================================================
Total params: 256,745
Trainable params: 256,745
Non-trainable params: 0
__________________________________________________________________________________________________
None
======================================
Skynnet Info: Longitud de los datos de la subred (datos,etiquetas): 48 48
Skynnet Info: Categorias de esta subred [1 2]
======================================
num patches=  36
Model: "model_2"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_3 (InputLayer)           [(None, 36, 36, 3)]  0           []                               
                                                                                                  
 data_augmentation (Sequential)  (None, 36, 36, 3)   0           ['input_3[0][0]']                
                                                                                                  
 patches_2 (Patches)            (None, None, 108)    0           ['data_augmentation[0][0]']      
                                                                                                  
 patch_encoder_2 (PatchEncoder)  (None, 36, 22)      3190        ['patches_2[0][0]']              
                                                                                                  
 layer_normalization_14 (LayerN  (None, 36, 22)      44          ['patch_encoder_2[0][0]']        
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_6 (MultiH  (None, 36, 22)      16038       ['layer_normalization_14[0][0]', 
 eadAttention)                                                    'layer_normalization_14[0][0]'] 
                                                                                                  
 add_12 (Add)                   (None, 36, 22)       0           ['multi_head_attention_6[0][0]', 
                                                                  'patch_encoder_2[0][0]']        
                                                                                                  
 layer_normalization_15 (LayerN  (None, 36, 22)      44          ['add_12[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 dense_19 (Dense)               (None, 36, 512)      11776       ['layer_normalization_15[0][0]'] 
                                                                                                  
 dropout_16 (Dropout)           (None, 36, 512)      0           ['dense_19[0][0]']               
                                                                                                  
 dense_20 (Dense)               (None, 36, 22)       11286       ['dropout_16[0][0]']             
                                                                                                  
 dropout_17 (Dropout)           (None, 36, 22)       0           ['dense_20[0][0]']               
                                                                                                  
 add_13 (Add)                   (None, 36, 22)       0           ['dropout_17[0][0]',             
                                                                  'add_12[0][0]']                 
                                                                                                  
 layer_normalization_16 (LayerN  (None, 36, 22)      44          ['add_13[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_7 (MultiH  (None, 36, 22)      16038       ['layer_normalization_16[0][0]', 
 eadAttention)                                                    'layer_normalization_16[0][0]'] 
                                                                                                  
 add_14 (Add)                   (None, 36, 22)       0           ['multi_head_attention_7[0][0]', 
                                                                  'add_13[0][0]']                 
                                                                                                  
 layer_normalization_17 (LayerN  (None, 36, 22)      44          ['add_14[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 dense_21 (Dense)               (None, 36, 512)      11776       ['layer_normalization_17[0][0]'] 
                                                                                                  
 dropout_18 (Dropout)           (None, 36, 512)      0           ['dense_21[0][0]']               
                                                                                                  
 dense_22 (Dense)               (None, 36, 22)       11286       ['dropout_18[0][0]']             
                                                                                                  
 dropout_19 (Dropout)           (None, 36, 22)       0           ['dense_22[0][0]']               
                                                                                                  
 add_15 (Add)                   (None, 36, 22)       0           ['dropout_19[0][0]',             
                                                                  'add_14[0][0]']                 
                                                                                                  
 layer_normalization_18 (LayerN  (None, 36, 22)      44          ['add_15[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 multi_head_attention_8 (MultiH  (None, 36, 22)      16038       ['layer_normalization_18[0][0]', 
 eadAttention)                                                    'layer_normalization_18[0][0]'] 
                                                                                                  
 add_16 (Add)                   (None, 36, 22)       0           ['multi_head_attention_8[0][0]', 
                                                                  'add_15[0][0]']                 
                                                                                                  
 layer_normalization_19 (LayerN  (None, 36, 22)      44          ['add_16[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 dense_23 (Dense)               (None, 36, 512)      11776       ['layer_normalization_19[0][0]'] 
                                                                                                  
 dropout_20 (Dropout)           (None, 36, 512)      0           ['dense_23[0][0]']               
                                                                                                  
 dense_24 (Dense)               (None, 36, 22)       11286       ['dropout_20[0][0]']             
                                                                                                  
 dropout_21 (Dropout)           (None, 36, 22)       0           ['dense_24[0][0]']               
                                                                                                  
 add_17 (Add)                   (None, 36, 22)       0           ['dropout_21[0][0]',             
                                                                  'add_16[0][0]']                 
                                                                                                  
 layer_normalization_20 (LayerN  (None, 36, 22)      44          ['add_17[0][0]']                 
 ormalization)                                                                                    
                                                                                                  
 flatten_2 (Flatten)            (None, 792)          0           ['layer_normalization_20[0][0]'] 
                                                                                                  
 dropout_22 (Dropout)           (None, 792)          0           ['flatten_2[0][0]']              
                                                                                                  
 dense_25 (Dense)               (None, 171)          135603      ['dropout_22[0][0]']             
                                                                                                  
 dropout_23 (Dropout)           (None, 171)          0           ['dense_25[0][0]']               
                                                                                                  
 dense_26 (Dense)               (None, 2)            344         ['dropout_23[0][0]']             
                                                                                                  
==================================================================================================
Total params: 256,745
Trainable params: 256,745
Non-trainable params: 0
__________________________________________________________________________________________________
None
